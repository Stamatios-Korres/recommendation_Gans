{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nfc.src.mlp import MLP as mlp\n",
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1036</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1079</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1090</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1196</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1112484742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1198</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1112484624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>1214</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>1215</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094786082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1219</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1240</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>1249</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>1258</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1259</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1266</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>1321</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094786062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>1358</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>1374</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1094785746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>1387</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112484913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1967</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1112485739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000223</th>\n",
       "      <td>138493</td>\n",
       "      <td>47465</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1256680620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000224</th>\n",
       "      <td>138493</td>\n",
       "      <td>48043</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256749799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000225</th>\n",
       "      <td>138493</td>\n",
       "      <td>48082</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1258390139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000226</th>\n",
       "      <td>138493</td>\n",
       "      <td>48229</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1255816542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000228</th>\n",
       "      <td>138493</td>\n",
       "      <td>48385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255817767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000229</th>\n",
       "      <td>138493</td>\n",
       "      <td>48516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255815874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000230</th>\n",
       "      <td>138493</td>\n",
       "      <td>48780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255804799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000231</th>\n",
       "      <td>138493</td>\n",
       "      <td>49651</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255817985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000235</th>\n",
       "      <td>138493</td>\n",
       "      <td>51662</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1255856908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000236</th>\n",
       "      <td>138493</td>\n",
       "      <td>51884</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256294768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000237</th>\n",
       "      <td>138493</td>\n",
       "      <td>52579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255856957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000238</th>\n",
       "      <td>138493</td>\n",
       "      <td>52975</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1256680293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000239</th>\n",
       "      <td>138493</td>\n",
       "      <td>53123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255816320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000241</th>\n",
       "      <td>138493</td>\n",
       "      <td>53322</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255812146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000242</th>\n",
       "      <td>138493</td>\n",
       "      <td>53464</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260209920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000243</th>\n",
       "      <td>138493</td>\n",
       "      <td>53996</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1259865104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000244</th>\n",
       "      <td>138493</td>\n",
       "      <td>55269</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255816088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000245</th>\n",
       "      <td>138493</td>\n",
       "      <td>55814</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255811181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000248</th>\n",
       "      <td>138493</td>\n",
       "      <td>58879</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1255816798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000249</th>\n",
       "      <td>138493</td>\n",
       "      <td>59315</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255818138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000251</th>\n",
       "      <td>138493</td>\n",
       "      <td>59784</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1255816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000252</th>\n",
       "      <td>138493</td>\n",
       "      <td>60069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1258134687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000253</th>\n",
       "      <td>138493</td>\n",
       "      <td>60816</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1259865163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000254</th>\n",
       "      <td>138493</td>\n",
       "      <td>61160</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1258390537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000255</th>\n",
       "      <td>138493</td>\n",
       "      <td>65682</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1255816373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000256</th>\n",
       "      <td>138493</td>\n",
       "      <td>66762</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1255805408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000257</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1260209720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>138493</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1258126920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>138493</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1259865108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>138493</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1258126944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9995410 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp\n",
       "6              1      151     4.0  1094785734\n",
       "7              1      223     4.0  1112485573\n",
       "8              1      253     4.0  1112484940\n",
       "9              1      260     4.0  1112484826\n",
       "10             1      293     4.0  1112484703\n",
       "11             1      296     4.0  1112484767\n",
       "12             1      318     4.0  1112484798\n",
       "15             1      541     4.0  1112484603\n",
       "22             1     1036     4.0  1112485480\n",
       "23             1     1079     4.0  1094785665\n",
       "26             1     1090     4.0  1112485453\n",
       "27             1     1097     4.0  1112485701\n",
       "30             1     1196     4.5  1112484742\n",
       "31             1     1198     4.5  1112484624\n",
       "32             1     1200     4.0  1112484560\n",
       "35             1     1214     4.0  1094785977\n",
       "36             1     1215     4.0  1094786082\n",
       "38             1     1219     4.0  1094785994\n",
       "40             1     1240     4.0  1112485401\n",
       "43             1     1249     4.0  1112485382\n",
       "44             1     1258     4.0  1094785994\n",
       "45             1     1259     4.0  1112485440\n",
       "48             1     1266     4.0  1112485371\n",
       "49             1     1278     4.0  1094785986\n",
       "52             1     1321     4.0  1094786062\n",
       "53             1     1333     4.0  1112484990\n",
       "56             1     1358     4.0  1112485419\n",
       "58             1     1374     4.0  1094785746\n",
       "59             1     1387     4.0  1112484913\n",
       "65             1     1967     4.0  1112485739\n",
       "...          ...      ...     ...         ...\n",
       "20000223  138493    47465     5.0  1256680620\n",
       "20000224  138493    48043     4.5  1256749799\n",
       "20000225  138493    48082     5.0  1258390139\n",
       "20000226  138493    48229     4.5  1255816542\n",
       "20000228  138493    48385     5.0  1255817767\n",
       "20000229  138493    48516     5.0  1255815874\n",
       "20000230  138493    48780     5.0  1255804799\n",
       "20000231  138493    49651     4.0  1255817985\n",
       "20000235  138493    51662     4.5  1255856908\n",
       "20000236  138493    51884     4.5  1256294768\n",
       "20000237  138493    52579     4.0  1255856957\n",
       "20000238  138493    52975     4.0  1256680293\n",
       "20000239  138493    53123     4.0  1255816320\n",
       "20000241  138493    53322     4.0  1255812146\n",
       "20000242  138493    53464     4.0  1260209920\n",
       "20000243  138493    53996     4.5  1259865104\n",
       "20000244  138493    55269     5.0  1255816088\n",
       "20000245  138493    55814     5.0  1255811181\n",
       "20000248  138493    58879     4.5  1255816798\n",
       "20000249  138493    59315     4.0  1255818138\n",
       "20000251  138493    59784     5.0  1255816901\n",
       "20000252  138493    60069     4.0  1258134687\n",
       "20000253  138493    60816     4.5  1259865163\n",
       "20000254  138493    61160     4.0  1258390537\n",
       "20000255  138493    65682     4.5  1255816373\n",
       "20000256  138493    66762     4.5  1255805408\n",
       "20000257  138493    68319     4.5  1260209720\n",
       "20000258  138493    68954     4.5  1258126920\n",
       "20000259  138493    69526     4.5  1259865108\n",
       "20000261  138493    70286     5.0  1258126944\n",
       "\n",
       "[9995410 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = '/home/timos/Downloads/'\n",
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'ratings.csv'), header=0)\n",
    "raw_data = raw_data[raw_data['rating'] > 3.5]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    # Only keep the triplets for items which were clicked on by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who clicked on at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 9990682 watching events from 136677 users and 20720 movies (sparsity: 0.353%)\n"
     ]
    }
   ],
   "source": [
    "#Only keep items that are clicked on by at least 5 users\n",
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data)\n",
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "user_activity\n",
    "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))\n",
    "\n",
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "\n",
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     1,      2,      3,      4,      5,      6,      7,      8,\n",
       "                 9,     10,\n",
       "            ...\n",
       "            138483, 138484, 138485, 138486, 138487, 138489, 138490, 138491,\n",
       "            138492, 138493],\n",
       "           dtype='int64', name='userId', length=136677)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_activity.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = map(lambda x: profile2id[x], tp['userId'])\n",
    "    sid = map(lambda x: show2id[x], tp['movieId'])\n",
    "    return pd.DataFrame(data={'uid': list(uid), 'sid': list(sid)}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([134677, 134677, 134677, ..., 135470, 135470, 135470])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_te.uid.values.max()\n",
    "test_data_te.uid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers and imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import mf\n",
    "from nfc.src.mlp import MLP as mlp\n",
    "from scipy.sparse import csr_matrix\n",
    "from mf import MF \n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pytorch.torchmf import BasePipeline,bpr_loss,BPRModule,PairwiseInteractions\n",
    "from scipy.sparse import coo_matrix\n",
    "import torch\n",
    "\n",
    "train_data = pd.read_csv('ml-20m/pro_sg/train.csv')\n",
    "test_data_tr = pd.read_csv('ml-20m/pro_sg/test_tr.csv')\n",
    "users = 136677 \n",
    "movies = 20720\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_train = train_data.uid.values\n",
    "movies_train = train_data.sid.values\n",
    "data_train = np.ones((users_train.shape[0]))\n",
    "coo_train = coo_matrix((data_train, (users_train,movies_train)),shape=(users, movies))\n",
    "\n",
    "#Dimensions of the coo_matrix (Users x Movies)\n",
    "n_test_users = test_data_tr.uid.unique()\n",
    "n_test_movies =  test_data_tr.sid.unique()\n",
    "\n",
    "users_test = test_data_tr.uid.values\n",
    "movies_test = test_data_tr.sid.values\n",
    "data_test = np.ones((users_test.shape[0]))\n",
    "coo_test = coo_matrix((data_test, (users_test,movies_test)),shape=(users, movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = BasePipeline(train= coo_train, test=coo_test, verbose=True,\n",
    "                        batch_size=1024, num_workers=4,\n",
    "                        n_factors=20, weight_decay=0,\n",
    "                        dropout_p=0., lr=.2, sparse=True,\n",
    "                        optimizer=torch.optim.SGD, n_epochs=40,\n",
    "                        random_seed=2017, loss_function=bpr_loss,\n",
    "                        model=BPRModule, hogwild=True,\n",
    "                        interaction_class=PairwiseInteractions,\n",
    "                        eval_metrics=('auc', 'patk'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from spotlight.datasets.movielens import get_movielens_dataset,_get_movielens\n",
    "from utils.helper_functions import make_implicit\n",
    "from utils.arg_extractor import get_args\n",
    "from spotlight.datasets import _transport\n",
    "from spotlight.interactions import Interactions\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users,items,ratings,timestamps =(_get_movielens('movielens_20M'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Interactions(users,items,ratings,timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (138494 users x 26745 items x 9990682 interactions)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DataSet MovieLens_100K will be used\n",
      "Data will be read from file: datasets/movielens/movielens_100K.hdf5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.datasets.movielens import get_movielens_dataset\n",
    "from spotlight.evaluation import rmse_score,precision_recall_score\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.factorization.representations import BilinearNet\n",
    "from utils.helper_functions import make_implicit\n",
    "import logging\n",
    "import spotlight.optimizers as optimizers\n",
    "\n",
    "dataset_name = '100K'\n",
    "\n",
    "\n",
    "logging.info(\"DataSet MovieLens_%s will be used\"%dataset_name)\n",
    "\n",
    "path = 'datasets/movielens/'\n",
    "\n",
    "dataset = get_movielens_dataset(variant=dataset_name,path=path)\n",
    "\n",
    "# ------------------- #\n",
    "#Transform the dataset to implicit feedback\n",
    "\n",
    "dataset = make_implicit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Interactions dataset (938 users x 1447 items x 55361 interactions)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "\"\"\"\n",
    "Shamelessly stolen from\n",
    "https://github.com/maciejkula/triplet_recommendations_keras\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_test_split(interactions, n=10):\n",
    "    \"\"\"\n",
    "    Split an interactions matrix into training and test sets.\n",
    "    Parameters\n",
    "    ----------\n",
    "    interactions : np.ndarray\n",
    "    n : int (default=10)\n",
    "        Number of items to select / row to place into test.\n",
    "    Returns\n",
    "    -------\n",
    "    train : np.ndarray\n",
    "    test : np.ndarray\n",
    "    \"\"\"\n",
    "    test = np.zeros(interactions.shape)\n",
    "    train = interactions.copy()\n",
    "    for user in range(interactions.shape[0]):\n",
    "        if interactions[user, :].nonzero()[0].shape[0] > n:\n",
    "            test_interactions = np.random.choice(interactions[user, :].nonzero()[0],\n",
    "                                                 size=n,\n",
    "                                                 replace=False)\n",
    "            train[user, test_interactions] = 0.\n",
    "            test[user, test_interactions] = interactions[user, test_interactions]\n",
    "\n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def _get_data_path():\n",
    "    \"\"\"\n",
    "    Get path to the movielens dataset file.\n",
    "    \"\"\"\n",
    "    data_path = os.path.join(os.path.dirname(os.path.abspath('__file__')),\n",
    "                        'data')\n",
    "    if not os.path.exists(data_path):\n",
    "        print('Making data path')\n",
    "        os.mkdir(data_path)\n",
    "    return data_path\n",
    "\n",
    "\n",
    "def _download_movielens(dest_path):\n",
    "    \"\"\"\n",
    "    Download the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "    req = requests.get(url, stream=True)\n",
    "\n",
    "    print('Downloading MovieLens data')\n",
    "\n",
    "    with open(os.path.join(dest_path, 'ml-100k.zip'), 'wb') as fd:\n",
    "        for chunk in req.iter_content(chunk_size=None):\n",
    "            fd.write(chunk)\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(dest_path, 'ml-100k.zip'), 'r') as z:\n",
    "        z.extractall(dest_path)\n",
    "\n",
    "\n",
    "def read_movielens_df():\n",
    "    path = _get_data_path()\n",
    "    zipfile = os.path.join(path, 'ml-100k.zip')\n",
    "    if not os.path.isfile(zipfile):\n",
    "        _download_movielens(path)\n",
    "    fname = os.path.join(path, 'ml-100k', 'u.data')\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    df = pd.read_csv(fname, sep='\\t', names=names)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_movielens_interactions():\n",
    "    df = read_movielens_df()\n",
    "\n",
    "    n_users = df.user_id.unique().shape[0]\n",
    "    n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "    interactions = np.zeros((n_users, n_items))\n",
    "    for row in df.itertuples():\n",
    "        interactions[row[1] - 1, row[2] - 1] = row[3]\n",
    "    return interactions\n",
    "\n",
    "\n",
    "def get_movielens_train_test_split(implicit=False):\n",
    "    interactions = get_movielens_interactions()\n",
    "    print(interactions)\n",
    "    if implicit:\n",
    "        interactions = (interactions >= 4).astype(np.float32)\n",
    "    train, test = train_test_split(interactions)\n",
    "    train = sp.coo_matrix(train)\n",
    "    test = sp.coo_matrix(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making data path\n",
      "Downloading MovieLens data\n"
     ]
    }
   ],
   "source": [
    "train,test = get_movielens_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 90570 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9430 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
